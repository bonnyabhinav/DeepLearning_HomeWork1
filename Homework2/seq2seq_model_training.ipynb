{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQjUBXqPtuVv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30887b9b-ff3a-41fb-e84d-9e5f43c2e2dc"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTXiPHn0lOk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import helpers\n",
        "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple\n",
        "\n",
        "#Caption Preprocessing\n",
        "#Creating two python dictionaries, word_to_index and index_to_word\n",
        "#we will represent every unique word in the vocab by an integer\n",
        "def vocab():\n",
        "  filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "  vocab=[]\n",
        "  captions=[]\n",
        "  caption_list=[]\n",
        "  count = []\n",
        "  file_names=[]\n",
        "  video_feature_dict={} #dict containing video features for every video ids\n",
        "  video_caption_dict={} #dict containing captions for every video ids\n",
        "\n",
        "  with open('training_label.json') as f:\n",
        "    training_labels = json.load(f)\n",
        "\n",
        "  for train in training_labels:\n",
        "    captions.append(train['caption'])\n",
        "    file_names.append(train['id'])\n",
        "    video_caption_dict[train['id']] = train['caption'] \n",
        "  \n",
        "  for i in range(len(captions)):\n",
        "    count.append(len(captions[i]))\n",
        "\n",
        "  for i in range(len(captions)):\n",
        "    for j in range(count[i]):\n",
        "      caption_list.append(captions[i][j])\n",
        "  \n",
        "\n",
        "  for files in range(1):\n",
        "    features = np.load(str(file_names[files])+'.npy')\n",
        "    video_feature_dict[files] = features\n",
        "\n",
        "  for w in caption_list:\n",
        "    for f in filters:\n",
        "      w = w.replace(f, '')\n",
        "\n",
        "    words = w.split(' ')\n",
        "    for v in words:\n",
        "      vo = v.replace('.','')\n",
        "      vocab.append(vo)\n",
        "\n",
        "  c=Counter(vocab)\n",
        "  unique = [w for w in vocab if c[w] == 1]\n",
        "\n",
        "  return unique, caption_list, video_feature_dict, video_caption_dict\n",
        "\n",
        "def indexing(vocab):\n",
        "  #the vocab here is the unique words from the captions\n",
        "  ixtoword = {} #index to word\n",
        "  wordtoix = {} #word to index\n",
        "\n",
        "  ixtoword[0] = '<pad>'\n",
        "  ixtoword[1] = '<bos>'\n",
        "  ixtoword[2] = '<eos>'\n",
        "  ixtoword[3] = '<unk>'\n",
        "\n",
        "  wordtoix['<pad>'] = 0\n",
        "  wordtoix['<bos>'] = 1\n",
        "  wordtoix['<eos>'] = 2\n",
        "  wordtoix['<unk>'] = 3\n",
        "\n",
        "  ix = 0\n",
        "  for w in vocab:\n",
        "    wordtoix[w] = ix+4\n",
        "    ixtoword[ix] = w\n",
        "    ix += 1\n",
        "  \n",
        "  return ixtoword, wordtoix\n",
        "\n",
        "def caption_details(caption_list):\n",
        "  cap_length = []\n",
        "  for i in range(len(caption_list)):\n",
        "    count = 1\n",
        "    for x in caption_list[i]:\n",
        "      if(x == ' '):\n",
        "        count +=1\n",
        "    cap_length.append(count)\n",
        "\n",
        "  print(sum(cap_length)/len(cap_length))\n",
        "\n",
        "  maximum = max(cap_length)\n",
        "  average = sum(cap_length)/len(cap_length)\n",
        "\n",
        "  return maximum, average\n",
        "\n",
        "def next_feed(batches):\n",
        "    batch = next(batches)\n",
        "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch)\n",
        "    decoder_targets_, _ = helpers.batch(\n",
        "        [(sequence) + [EOS] + [PAD] for sequence in batch]\n",
        "    )\n",
        "    return {\n",
        "        encoder_inputs: encoder_inputs_,\n",
        "        encoder_inputs_length: encoder_input_lengths_,\n",
        "        decoder_targets: decoder_targets_,\n",
        "    }\n",
        "\n",
        "\n",
        "def training_model(word_size, max_length, feature_length):\n",
        "  tf.set_random_seed(9487)\n",
        "  vocab_size = word_size\n",
        "  encoder_input_size = feature_length\n",
        "  decoder_output_size = max_length\n",
        "  encoder_hidden_units = 20\n",
        "  decoder_hidden_units = 20\n",
        "\n",
        "  encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
        "  encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
        "  decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
        "\n",
        "  embeddings = tf.Variable(tf.random_uniform([vocab_size, encoder_input_size], -1.0, 1.0), dtype=tf.float32)\n",
        "  encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
        "\n",
        "  encoder_cell = LSTMCell(encoder_hidden_units)\n",
        "\n",
        "  encoder_outputs, encoder_final_state = (tf.nn.dynamic_rnn(cell=encoder_cell,\n",
        "                      inputs=encoder_inputs_embedded, \n",
        "                      sequence_length=encoder_inputs_length,\n",
        "                      dtype=tf.float32, time_major=True))\n",
        "\n",
        "\n",
        "  decoder_cell = LSTMCell(decoder_hidden_units)\n",
        "  encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))\n",
        "  decoder_lengths = encoder_inputs_length + 3\n",
        "\n",
        "  attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
        "                units=self.rnn_size, \n",
        "                memory=encoder_outputs,\n",
        "                memory_sequence_length=encoder_inputs_length)\n",
        "  \n",
        "  decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
        "                cell=decoder_cell, \n",
        "                attention_mechanism=attention_mechanism, \n",
        "                attention_layer_size=self.rnn_size, \n",
        "                name='Attention_Wrapper')\n",
        "\n",
        "  #weights\n",
        "  W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype=tf.float32)\n",
        "  #bias\n",
        "  b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)\n",
        "\n",
        "\n",
        "  assert EOS == 1 and PAD == 0\n",
        "\n",
        "  eos_time = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
        "  pad_time = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
        "\n",
        "  #retrieves rows of the params tensor. The behavior is similar to using indexing with arrays in numpy\n",
        "  embeddings = tf.Variable(tf.random_uniform([vocab_size, decoder_intput_size], -1.0, 1.0), dtype=tf.float32)\n",
        "  decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_outputs)\n",
        "\n",
        "  decoder_outputs, decoder_final_state = (tf.nn.dynamic_rnn(cell=decoder_cell,\n",
        "                      inputs=decoder_inputs_embedded, \n",
        "                      sequence_length= decoder_lengths,\n",
        "                      dtype=tf.float32, time_major=True))\n",
        "\n",
        "  decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
        "  decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
        "\n",
        "  decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
        "  decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))\n",
        "\n",
        "  decoder_prediction = tf.argmax(decoder_logits, 2)\n",
        "\n",
        "  stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
        "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
        "    logits=decoder_logits,\n",
        "  )\n",
        "  #loss function\n",
        "  loss = tf.reduce_mean(stepwise_cross_entropy)\n",
        "  #train it \n",
        "  train_op = tf.train.AdamOptimizer().minimize(loss)\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  batch_size = 100\n",
        "\n",
        "  batches = helpers.random_sequences(length_from=3, length_to=8,\n",
        "                                   vocab_lower=2, vocab_upper=10,\n",
        "                                   batch_size=batch_size)\n",
        "\n",
        "  max_batches = 1972\n",
        "\n",
        "  for batch in range(max_batches):\n",
        "    fd = next_feed(batches)\n",
        "    _, l = sess.run([train_op, loss], fd)\n",
        "    losses.append(l)\n",
        "\n",
        "  if batch == 0 or batch % 100 == 0:\n",
        "    print('batch {}'.format(batch))\n",
        "    print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
        "    predict_ = sess.run(decoder_prediction, fd)\n",
        "    for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
        "      print('    predicted > {}'.format(pred))\n",
        "      if i >= 2:\n",
        "        break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  #things to do here\n",
        "  #getting the video_caption_dict and video_feature_dict\n",
        "  #getting wordtoix and ixtoword\n",
        "  #captions_words_set unique words in the captions\n",
        "  #max_captions_length\n",
        "  #avg_captions_length\n",
        "  #num_unique_tokens_captions\n",
        "  print(\"This is just a start\")\n",
        "  unique_words, caption_list, video_feature_dict, video_caption_dict = vocab()\n",
        "  ixtoword, wordtoix = indexing(unique_words)\n",
        "  max_captions_length, average_captions_length = caption_details(caption_list)\n",
        "  unique_words_count = len(unique_words)\n",
        "\n",
        "\n",
        "  print(\"Maximum Caption Length\",max_captions_length)\n",
        "  print(\"Average Caption Length\",average_captions_length)\n",
        "  print(\"Total number of unique words\",unique_words_count)\n",
        "\n",
        "  training_model(unique_words_count, max_captions_length, len(video_feature_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}