{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "APUPK5rp8oRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqfWUDXwCfwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z82i64ucEknS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_dataset = tf.data.Dataset.from_tensor_slices(mnist_train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "def training_batches():\n",
        "  path = \"C:\\\\Users\\\\abhin\\\\Downloads\\\\cifar-10-batches-py\"\n",
        "  file = \"data_batch_1\"\n",
        "  #file = pd.concat(file,next)\n",
        "\n",
        "  #file_path = os.path.join(path,file)\n",
        "\n",
        "  with open(file, 'rb') as fo:\n",
        "    training_batch = pickle.load(fo, encoding='bytes')  #retruns a dictionary\n",
        "  \n",
        "  features = training_batch[b'data']\n",
        "  labels = training_batch[b'labels']\n",
        "  return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS81ttNMt5LD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd gdrive/My \\Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X41UrLmkNEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# N refers to the number of images in a batch, \n",
        "#H refers to the number of pixels in the vertical dimension, \n",
        "#W refers to the number of pixels in the horizontal dimension, \n",
        "#and C refers to the channels (e.g. 1 for black and white, 3 for RGB, etc.\n",
        "\n",
        "#*************************************************************************#\n",
        "\n",
        "#Some information about the dataset\n",
        "#Data: 10000x3072 numpy array of uint8s. Each row stores a 32x32 color image\n",
        "      #The first 1024 contains red channel values\n",
        "      #Next 1024 contains green channel values\n",
        "      #Final 1024 contains the blue channel values\n",
        "      #The image is stored in row-major order, so that the first 32 entries\n",
        "      #of the array are the red channel values of the first row of the image\n",
        "#Labels: 10000 numbers in the range 0-9. The number at index i indicates the \n",
        "        # label of the ith image in the array data\n",
        "#Label_names: A 10-element list which gives meaningful names to the numeric\n",
        "            #labels in the labels array described above. For example \n",
        "            #label_names[0] == \"airplane\", label_name[1] == \"automobile\"\n",
        "\n",
        "#*************************************************************************#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K4iOWIaE8df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGAN():\n",
        "  def __init__(self):\n",
        "    self.batch_size = 10000\n",
        "    self.image_size = 32*32\n",
        "    self.image_channels = 3\n",
        "  \n",
        "  def inputs(self):\n",
        "    x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_x')\n",
        "    z = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='noise')\n",
        "    prob = tf.placeholder(tf.float32, name='prob')\n",
        "\n",
        "    return x, z, prob\n",
        "\n",
        "  def dcgan_generator_model(self, input, reuse = False):\n",
        "    with tf.variable_scope(\"dcgan_generator_model\") as scope:\n",
        "      if reuse:\n",
        "        scope.reuse_variables()\n",
        "   \n",
        "    #tf.nn.conv2d_transpose(input, filters, output_shape, strides, padding='SAME', data_format='NHWC',dilations=None, name=None)\n",
        "    #First Convolution Layer\n",
        "    g_conv_layer1 = tf.nn.conv2d_transpose(input, [None, 32, 32, 3], [1,2,2,1]) #Added by Abhinav \n",
        "    g_conv_layer1 = tf.nn.relu(tf.contrib.layers.batch_norm(g_conv_layer1,decay = 0.9, epsilon=1e-5))\n",
        "\n",
        "    #Second Convolution Layer\n",
        "    g_conv_layer2 = tf.nn.conv2d_transpose(g_conv_layer1, [None, 32, 32, 3], [1,2,2,1])\n",
        "    g_conv_layer2 = tf.nn.relu(tf.contrib.layers.batch_norm(g_conv_layer2,decay = 0.9, epsilon=1e-5))\n",
        "\n",
        "    #Thrid Convolution Layer\n",
        "    g_conv_layer3 = tf.nn.conv2d_transpose(g_conv_layer2, [None, 32, 32, 3], [1,2,2,1])\n",
        "    g_conv_layer3 = tf.nn.relu(tf.contrib.layers.batch_norm(g_conv_layer3,decay = 0.9, epsilon=1e-5))\n",
        "\n",
        "    #Fourth Convolution Layer\n",
        "    g_conv_layer4 = tf.nn.conv2d_transpose(g_conv_layer3, [None, 32, 32, 3], [1,2,2,1])\n",
        "    g_conv_layer4 = tf.nn.relu(tf.contrib.layers.batch_norm(g_conv_layer4,decay = 0.9, epsilon=1e-5))\n",
        "\n",
        "    output = tf.nn.tanh(g_conv_layer4) #if the dataset is the MNIST\n",
        "\n",
        "    return output\n",
        "\n",
        "  def dcgan_discriminator_model(self, input, reuse = False):\n",
        "\n",
        "    with tf.variable_scope(\"discriminator\") as scope:\n",
        "      if reuse:\n",
        "        scope.reuse_variables()\n",
        "    \n",
        "    #First Convoultion Layer\n",
        "    d_conv1 = tf.nn.conv2d(input, strides = [1, 2, 2, 1], padding='SAME')\n",
        "    d_conv1 = tf.nn.leaky_relu(d_conv1, alpha = 0.2)\n",
        "\n",
        "    #Second Convolution Layer\n",
        "    d_conv2 = tf.nn.conv2d(d_conv1, strides = [1, 2, 2, 1], padding='SAME')\n",
        "    d_conv2 = tf.nn.leaky_relu(tf.contrib.layers.batch_norm(d_conv2, decay=0.9, epsilon=1e-5), alpha = 0.2)\n",
        "\n",
        "    #Third Convolution Layer\n",
        "    d_conv3 = tf.nn.conv2d(d_conv2, strides = [1, 2, 2, 1], padding='SAME')\n",
        "    d_conv3 = tf.nn.leaky_relu(tf.contrib.layers.batch_norm(d_conv3, decay=0.9, epsilon=1e-5), alpha = 0.2)\n",
        "\n",
        "    #Fourth Convolution Layer\n",
        "    d_conv4 = tf.nn.conv2d(d_conv3, strides = [1, 2, 2, 1], padding='SAME')\n",
        "    d_conv4 = tf.nn.leaky_relu(tf.contrib.layers.batch_norm(d_conv4, decay=0.9, epsilon=1e-5), alpha = 0.2)\n",
        "\n",
        "    hidden = tf.reshape(d_conv4, [10000, 32, 32, 3])\n",
        "\n",
        "    output = tf.nn.sigmoid(tf.matmul(hidden, D_FW1) + D_Fb1)\n",
        "\n",
        "    return output\n",
        "\n",
        "  def loss(self, x, z):\n",
        "    g_output = self.dcgan_generator_model(z)\n",
        "    d_fake = self.dcgan_discriminator_model(g_output, reuse= False)\n",
        "    d_real = self.dcgan_discriminator_model(x, reuse = True)\n",
        "\n",
        "    d_loss = tf.reduce_mean(tf.log(d_real)+tf.log(1 - d_fake))\n",
        "    g_loss = tf.reduce_mean(tf.log(d_fake))\n",
        "\n",
        "    return d_loss, g_loss\n",
        "\n",
        "  def optimizer(self, d_loss, g_loss):\n",
        "    d_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='discriminator')\n",
        "    g_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator')\n",
        "\n",
        "    d_opt = tf.train.AdamOptimizer(0.0002, beta1 = 0.5).minimize(-d_loss,\n",
        "                                                            var_list=d_var_list)\n",
        "    g_opt = tf.train.AdamOptimizer(0.0002, beta1 = 0.5).minimize(-g_loss,\n",
        "                                                            var_list=g_var_list)\n",
        "    return d_opt, g_opt\n",
        "\n",
        "  def sample(self, Z, reuse = True):\n",
        "    g_out=self.generator(Z, reuse=reuse)\n",
        "    return g_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gstAA1zJFFsj",
        "colab_type": "code",
        "outputId": "d101dd00-e525-4657-9a45-f3db7c291f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  #getting the training batch\n",
        "  \n",
        "  features, labels = training_batches()\n",
        "\n",
        "  input_x = tf.reshape(features, [10000, 32, 32, 3])\n",
        "  dcgan = DCGAN()\n",
        "  x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_x')\n",
        "  z = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='noise')\n",
        "  #x, z, probability = dcgan.inputs()\n",
        "  print(x.shape)\n",
        "  disc_loss, gen_loss = dcgan.loss(x, z)\n",
        "  disc_opt, gen_opt = dcgan.optimizer(disc_loss, g_loss)\n",
        "\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  sess = tf.Session()\n",
        "  sess.run(init)\n",
        "  writer = tf.summary.FileWriter(\"./log\", sess.graph)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    #Generator noise to feed the discriminator\n",
        "    z_noise = np.random.uniform(-1.,1., size = [10000, 3072])\n",
        "    for i in range(5):\n",
        "      _, Disc_loss_epoch = sess.run([disc_opt, disc_loss], feed_dict={x:input_x, z:z_noise})\n",
        "\n",
        "    _, Gen_loss_epoch = sess.run([gen_opt, gen_loss], feed_dict = {z_input:z_noise})\n",
        "\n",
        "    #running the Discriminatory summary\n",
        "    #summary_Disc_Loss = sess.run(Disc_loss_total, feed_dict = (x_input:x_batch,z_input:z_noise))\n",
        "    #Adding the Generator summary\n",
        "    writer.add_summary(Disc_loss_epoch, epoch)\n",
        "\n",
        "    #Running the Generator summary\n",
        "    #summary_Gen_Loss = sess.run(Gen_loss_total, feed_dict = (z_input:z_noise))\n",
        "    #Adding the Generator summary\n",
        "    writer.add_summary(Gen_loss_epoch, epoch)\n",
        "\n",
        "    if epoch % 2000 == 0:\n",
        "      print(\"steps: {0} : Generator_loss:{1} : Discriminator_loss:{2}\".format(epoch,Gen_loss_epoch,Disc_loss_epoch))\n",
        "\n",
        "\n",
        "    #Testing \n",
        "    #Generate images from noise, using the generator network\n",
        "    n=6\n",
        "    canvas = np.empty((28*n, 28*n))\n",
        "    for i in range(n):\n",
        "      #Noise input\n",
        "      z_noise = tf.random.uniform(-1.,1., size=[batch_size, z_noise_dim])\n",
        "      #Generate image from noise\n",
        "      g=sess.run(output_Gen, feed_dict={z_input:z_noise})\n",
        "      #Reverse colors for better display\n",
        "      g = -1 * (g-1)\n",
        "      for j in range(n):\n",
        "        #Draw the generated digits\n",
        "        canvas[i * 28:(i+1)*28, j * 28:(j+1)*28] = g[j].reshape([28,28])\n",
        "  \n",
        "    plt.figure(figsize=(n,n))\n",
        "    plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
        "    plt.show()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-12154a867caa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m#x, z, probability = dcgan.inputs()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mdisc_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-128-908e2dd70a98>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mg_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcgan_generator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0md_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcgan_discriminator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0md_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcgan_discriminator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-128-908e2dd70a98>\u001b[0m in \u001b[0;36mdcgan_generator_model\u001b[0;34m(self, input, reuse)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#tf.nn.conv2d_transpose(input, filters, output_shape, strides, padding='SAME', data_format='NHWC',dilations=None, name=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#First Convolution Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mg_conv_layer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_transpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Added by Abhinav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mg_conv_layer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_conv_layer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d_transpose\u001b[0;34m(value, filter, output_shape, strides, padding, data_format, name, input, filters, dilations)\u001b[0m\n\u001b[1;32m   2202\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d_transpose_v2\u001b[0;34m(input, filters, output_shape, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2273\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2274\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2275\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1405\u001b[0m                                \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m                                \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m                                name=name)\n\u001b[0m\u001b[1;32m   1408\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    630\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[1;32m    631\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                                        param_name=input_name)\n\u001b[0m\u001b[1;32m    633\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[0;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[1;32m     59\u001b[0m           \u001b[0;34m\"allowed values: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[0;32m---> 61\u001b[0;31m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Value passed to parameter 'filter' has DataType int32 not in list of allowed values: float16, bfloat16, float32, float64"
          ]
        }
      ]
    }
  ]
}