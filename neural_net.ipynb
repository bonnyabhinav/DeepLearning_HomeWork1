{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "35_eZL-V71E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@misc{TFDS,\n",
        "#title = { {TensorFlow Datasets}, A collection of ready-to-use datasets},\n",
        "#howpublished = {\\url{https://www.tensorflow.org/datasets}},\n",
        "#}\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnSbFlbe745X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_data = input_data.read_data_sets('MNIST_data',one_hot=True)\n",
        "mnist_train_images = mnist_data.train.images\n",
        "mnist_train_labels = mnist_data.train.labels\n",
        "mnist_test_images = mnist_data.test.images\n",
        "mnist_test_labels = mnist_data.test.labels\n",
        "input_mnist1 = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "output_mnist1 = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "\n",
        "input_mnist2 = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "output_mnist2 = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "\n",
        "input_mnist3 = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "output_mnist3 = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "\n",
        "model_loss1=[]\n",
        "model_loss2=[]\n",
        "epochs = 100\n",
        "model_acc1=[]\n",
        "model_acc2=[]\n",
        "train_iter = 8\n",
        "weights = []\n",
        "optimize=[]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5Wt81ix8UbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dimension_reduction(weight):\n",
        "  print(\"Inside this function:\")\n",
        "  pca = PCA(n_components=2)\n",
        "  p_comp = pca.fit_transform(weight)\n",
        "  p_df = pd.DataFrame(data = p_comp\n",
        "             , columns = ['x1', 'x2'])\n",
        "  plt.plot(p_df['x1'],p_df['x2'])\n",
        "  plt.title('weights 2-d plotting')\n",
        "  plt.xlabel('x1')\n",
        "  plt.ylabel('x2')\n",
        "  plt.show()\n",
        "\n",
        "  return True\n",
        "\n",
        "def accuracy_plotting(acc1, acc2):\n",
        "  plt.plot(acc1)\n",
        "  plt.plot(acc2)\n",
        "  plt.legend(['Model1', 'Model2'])\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.show()\n",
        "\n",
        "  return True\n",
        "\n",
        "def optimization_plotting(opt1,opt2):\n",
        "  plt.plot(opt1)\n",
        "  plt.plot(opt2)\n",
        "  plt.legend(['Model1', 'Model2'])\n",
        "  plt.title('Optimization')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Optimize')\n",
        "  plt.show()\n",
        "\n",
        "  return True\n",
        "\n",
        "def training_plotting():\n",
        "  _, axes = plt.subplots(2, 4)\n",
        "  images_and_labels = list(zip(mnist_train_images, mnist_train_labels))\n",
        "  for ax, (image, label) in zip(axes[0:, :], images_and_labels[:4]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image.reshape(28,28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title(\"Training\")\n",
        "  \n",
        "  plt.show()\n",
        "  return True\n",
        "\n",
        "def prediction_plotting(prediction):\n",
        "  _, axes = plt.subplots(2, 4)\n",
        "  images_and_predictions = list(zip(mnist_train_images, prediction))\n",
        "  for ax, (image, prediction) in zip(axes[0:, :], images_and_predictions[:4]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image.reshape(28,28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title(\"Prediction\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  return True\n",
        "\n",
        "def loss_plotting(loss1, loss2):\n",
        "  plt.plot(loss1)\n",
        "  plt.plot(loss2)\n",
        "  plt.legend(['Model1', 'Model2'])\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.show()\n",
        "\n",
        "  return True\n",
        "\n",
        "class deep_model1():\n",
        "  #Model1: Defining the layers of the model, no. of nodes in each layers, \n",
        "  #and activation function \n",
        "  #First model will have 3 layers 2 hidden layers with the activation function \n",
        "  #sigmoid no. of nodes in the first layer will be\n",
        " \n",
        "  def parameters(self):\n",
        "    total_parameters = 0\n",
        "    for variable in tf.trainable_variables():\n",
        "      # shape is an array of tf.Dimension\n",
        "      print(variable)\n",
        "      shape = variable.get_shape()\n",
        "      print(shape)\n",
        "      #print(len(shape))\n",
        "      variable_parameters = 1\n",
        "      for dim in shape:\n",
        "        #print(dim)\n",
        "        variable_parameters *= dim.value\n",
        "      print(variable_parameters)\n",
        "      total_parameters += variable_parameters\n",
        "    print(total_parameters)\n",
        "    return True\n",
        "  \n",
        "  def model1(self):\n",
        "    train_acc = []\n",
        "    p_label = []\n",
        "    model1_h1 = tf.layers.dense(inputs= input_mnist1, units=128, activation=tf.nn.sigmoid, name='model1_h1', reuse= None)   # hidden layer\n",
        "    model1_output = tf.layers.dense(inputs=model1_h1, units=10, name='model1_output', reuse=None)  #output layer       # output layer\n",
        "    self.parameters()\n",
        "    \n",
        "    loss = tf.losses.mean_squared_error(output_mnist1, model1_output)\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.05)\n",
        "    train_op = optimizer.minimize(loss)\n",
        "\n",
        "    sess = tf.Session()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    for epoch in range (3500):\n",
        "      inputs, labels = mnist_data.train.next_batch(5)\n",
        "      feeds = {input_mnist1: mnist_train_images, output_mnist1: mnist_train_labels}\n",
        "      op,l,pred = sess.run([train_op,loss,model1_output], feed_dict=feeds)\n",
        "      pred = tf.equal(tf.argmax(model1_output, 1), tf.argmax(output_mnist1, 1))\n",
        "      accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
        "      p_label.append(tf.cast(pred, tf.float32))\n",
        "      if epoch%2 == 0:\n",
        "        model_loss1.append(l)\n",
        "        optimize.append(op)\n",
        "        train_accuracy = accuracy.eval(session=sess, feed_dict=feeds)\n",
        "        print(\"Step %d, training batch accuracy %g\"%(epoch, train_accuracy))\n",
        "        train_acc.append(train_accuracy)\n",
        "\n",
        "    print(\"Test accuracy: %g\"%accuracy.eval(session=sess, feed_dict={input_mnist1: mnist_test_images, output_mnist1: mnist_test_labels}))\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess, \"/content/gdrive/My Drive/model1.ckpt\")\n",
        "    print(\"prediction label is here:\", p_label)\n",
        "    return model_loss1, train_acc, saver, p_label\n",
        "\n",
        "class deep_model2():\n",
        "  def parameters(self):\n",
        "    total_parameters = 0\n",
        "    for variable in tf.trainable_variables():\n",
        "      # shape is an array of tf.Dimension\n",
        "      print(variable)\n",
        "      shape = variable.get_shape()\n",
        "      print(shape)\n",
        "      #print(len(shape))\n",
        "      variable_parameters = 1\n",
        "      for dim in shape:\n",
        "        #print(dim)\n",
        "        variable_parameters *= dim.value\n",
        "      print(variable_parameters)\n",
        "      total_parameters += variable_parameters\n",
        "    print(total_parameters)\n",
        "    return True\n",
        "\n",
        "  def model2(self):\n",
        "    train_acc = []\n",
        "    p_label = []\n",
        "    model2_h1 = tf.layers.dense(inputs= input_mnist2, units=107, activation=tf.nn.sigmoid, name='model2_h1', reuse=None)# hidden layer\n",
        "    model2_h2 = tf.layers.dense(inputs= model2_h1, units=64, activation=tf.nn.sigmoid, name='model2_h2', reuse=None)    # hidden layer\n",
        "    model2_h3 = tf.layers.dense(inputs= model2_h2, units=16, activation=tf.nn.sigmoid, name='model2_h3', reuse=None)    # hidden layer\n",
        "    model2_output = tf.layers.dense(inputs=model2_h3, units=10, name='model2_output', reuse=None)                       # output layer\n",
        "    self.parameters()\n",
        "    loss = tf.losses.mean_squared_error(output_mnist2, model2_output)\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.05)\n",
        "    train_op = optimizer.minimize(loss)\n",
        "    sess2 = tf.Session()\n",
        "    sess2.run(tf.global_variables_initializer())\n",
        "    sess2.run(tf.local_variables_initializer())\n",
        "\n",
        "    for epoch in range (3500):\n",
        "      #train and net output\n",
        "      inputs, labels = mnist_data.train.next_batch(5)\n",
        "      feeds = {input_mnist2: mnist_train_images, output_mnist2: mnist_train_labels}\n",
        "      op,l,pred = sess2.run([train_op,loss,model2_output], feed_dict=feeds)\n",
        "      pred = tf.equal(tf.argmax(model2_output, 1), tf.argmax(output_mnist2, 1))\n",
        "      accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
        "      p_label.append(tf.cast(pred, tf.float32))\n",
        "\n",
        "      #printing batch accuracy after every 100 epochs\n",
        "      if epoch%2 == 0:\n",
        "        model_loss2.append(l)\n",
        "        optimize.append(op)\n",
        "        train_accuracy = accuracy.eval(session=sess2, feed_dict=feeds)\n",
        "        print(\"Step %d, training batch accuracy %g\"%(epoch, train_accuracy))\n",
        "        train_acc.append(train_accuracy)\n",
        "    print(\"Test accuracy: %g\"%accuracy.eval(session=sess2, feed_dict={input_mnist2: mnist_test_images, output_mnist2: mnist_test_labels}))\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess2, \"/content/gdrive/My Drive/model2.ckpt\")\n",
        "    \n",
        "    return model_loss2,train_acc, saver,p_label\n",
        "\n",
        "class deep_model3():\n",
        "  def parameters(self):\n",
        "    total_parameters = 0\n",
        "    for variable in tf.trainable_variables():\n",
        "      # shape is an array of tf.Dimension\n",
        "      print(variable)\n",
        "      shape = variable.get_shape()\n",
        "      print(shape)\n",
        "      #print(len(shape))\n",
        "      variable_parameters = 1\n",
        "      for dim in shape:\n",
        "        #print(dim)\n",
        "        variable_parameters *= dim.value\n",
        "      print(variable_parameters)\n",
        "      total_parameters += variable_parameters\n",
        "    print(total_parameters)\n",
        "    return True\n",
        "\n",
        "  def model3(self):\n",
        "    train_acc = []\n",
        "    p_label = []\n",
        "    model3_h1 = tf.layers.dense(inputs= input_mnist3, units=128, activation=tf.nn.tanh, name='model3_h1', reuse=None)# hidden layer\n",
        "    model3_h2 = tf.layers.dense(inputs= model3_h1, units=64, activation=tf.nn.tanh, name='model3_h2', reuse=None)    # hidden layer\n",
        "    model3_output = tf.layers.dense(inputs=model3_h2, units=10, name='model3_output', reuse=None)                       # output layer\n",
        "    self.parameters()\n",
        "    loss = tf.losses.mean_squared_error(output_mnist3, model3_output)\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.05)\n",
        "    train_op = optimizer.minimize(loss)\n",
        "    sess3 = tf.Session()\n",
        "    sess3.run(tf.global_variables_initializer())\n",
        "    sess3.run(tf.local_variables_initializer())\n",
        "\n",
        "    for epoch in range (3500):\n",
        "      #train and net output\n",
        "      inputs, labels = mnist_data.train.next_batch(5)\n",
        "      feeds = {input_mnist3: mnist_train_images, output_mnist3: mnist_train_labels}\n",
        "      op,l,pred = sess3.run([train_op,loss,model3_output], feed_dict=feeds)\n",
        "      pred = tf.equal(tf.argmax(model3_output, 1), tf.argmax(output_mnist3, 1))\n",
        "      accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
        "      p_label.append(tf.cast(pred, tf.float32))\n",
        "      print(\"Opt: \", op)\n",
        "      #printing batch accuracy after every 100 epochs\n",
        "      if epoch%10 == 0:\n",
        "        model_loss3.append(l)\n",
        "        optimize.append(op)\n",
        "        train_accuracy = accuracy.eval(session=sess2, feed_dict=feeds)\n",
        "        print(\"Step %d, training batch accuracy %g\"%(epoch, train_accuracy))\n",
        "        train_acc.append(train_accuracy)\n",
        "        #gradient = gradient_calc() #tf.estimator.EstimatorSpec(mode = tf.estimator.ModeKeys.TRAIN,loss=loss, train_op=train_op)\n",
        "    print(\"Test accuracy: %g\"%accuracy.eval(session=sess2, feed_dict={input_mnist2: mnist_test_images, output_mnist2: mnist_test_labels}))\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess3, \"/content/gdrive/My Drive/model2.ckpt\")\n",
        "    return model_loss3,train_acc, saver,p_label\n",
        "\n",
        "def main():\n",
        "  \n",
        "  dp1 = deep_model1()\n",
        "  dp2 = deep_model2()\n",
        "  dp3 = deep_model3()\n",
        "  #training the model for 8 times\n",
        "  for iter in range (train_iter):\n",
        "    loss_value_1, train_acc1, saved_sess1, pred1 = dp1.model1()\n",
        "    loss_value_2, train_acc2, saved_sess2, pred2 = dp2.model2()\n",
        "    loss_value_3, train_acc3, saved_sess3, pred3 = dp3.model3()\n",
        "    if iter%3 == 0:\n",
        "      print(\"Saving the session successfully\")#all the weights are stored\n",
        "      model1_weights_h1 = tf.get_collection(key = tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'model1_h1/kernel:0')\n",
        "      model1_weights_output = tf.get_collection(key = tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'model1_output/kernel:0')\n",
        "      model2_weights_h1 = tf.get_collection(key = tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'model2_h1/kernel:0')\n",
        "      model2_weights_h2 = tf.get_collection(key = tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'model2_h2/kernel:0')\n",
        "      model2_weights_h3 = tf.get_collection(key = tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'model2_h3/kernel:0')\n",
        "      model2_weights_output = tf.get_collection(key = tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'model2_output/kernel:0')\n",
        "      #get the weights from the sessions\n",
        "  loss_plotting(loss_value_1,loss_value_2)\n",
        "  loss_plotting(loss_value_1,loss_value_3)\n",
        "  accuracy_plotting(train_acc1,train_acc2)\n",
        "  accuracy_plotting(train_acc1,train_acc3)\n",
        "  training_plotting()\n",
        "  prediction_plotting(pred1)\n",
        "  #For Prediction plot of model2\n",
        "  prediction_plotting(pred2)\n",
        "  prediction_plotting(pred3) \n",
        "  loss_value_2 = dp2.model2()\n",
        "\n",
        "if __name__ ==\"__main__\":\n",
        "  main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}